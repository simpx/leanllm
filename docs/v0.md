LeanLLM v0
===========

目标
----
- 150行纯 PyTorch 实现推理
- 只依赖 PyTorch + Transformers（仅用于下载模型）

架构
----
```
leanllm/
  engine.py           # 统一推理接口
  models/
    base.py           # 原子层：Attention、MLP、RoPE
    gpt2.py           # GPT-2 模型结构 + 权重加载（84 行）
    __init__.py
main.py               # 命令行入口
```

实现细节
--------
- **engine.py**：`LLM` 类封装模型加载和推理，自动处理设备/dtype
- **models/base.py**：可复用的原子层
  - `Attention`：多头自注意力 + 可选 RoPE，用 `F.scaled_dot_product_attention`
  - `MLP`：两层全连接 + 可配置激活（GELU/SiLU）
  - `RotaryEmbedding`：RoPE 位置编码
- **models/gpt2.py**：
  - `GPT2`：Embedding + pos_embed -> 12×Block -> LayerNorm -> LM Head
  - `GPT2Block`：PreNorm + Attention + MLP（残差连接）
  - `load_gpt2_from_hf()`：从 HF state_dict 加载权重，处理 Conv1D 转 Linear 的转置
- **推理**：greedy decoding，单 batch，无 KV cache，自动判断 CUDA/CPU

支持模型
--------
- ✅ GPT-2（`openai-community/gpt2`）

用法
----
```python
from leanllm import LLM

llm = LLM("openai-community/gpt2")
output = llm.generate("Hello, I'm a language model,", max_new_tokens=30)
print(output)
```

命令行：
```bash
uv pip install -e .
uv run main.py --model openai-community/gpt2 --prompt "Hello" --max-new-tokens 20
```
